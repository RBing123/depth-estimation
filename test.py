# -*- coding: utf-8 -*-
"""test.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZVNFtHLUabA6NUyPgVZ0vHZ21TTZYq5j
"""

import pandas as pd
import cv2
import numpy as np
from google.colab import drive
drive.mount('/content/drive')

import matplotlib.pyplot as plt
train_image = []
cmap = "inferno_r"
plt.figure(figsize=(15,9))
for i in range(0,4):
  img_cv2 = cv2.imread('/content/drive/MyDrive/test_image/'+str(i)+'.jpg')
  image  = cv2.resize(img_cv2,(640,192),interpolation=cv2.INTER_AREA)
  train_image.append(image)
for i in range(0,4):
  image=train_image[i]
  image=cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
  plt.subplot(221+i)
  plt.axis('off')
  plt.imshow(image)
  plt.title('Input image')
  plt.axis('off')

img_cv2 = cv2.imread('/content/drive/MyDrive/test_image/3.jpg')
image  = cv2.resize(img_cv2,(640,192),interpolation=cv2.INTER_AREA)

!pip install tensorflow_addons
import tensorflow_addons

import tensorflow as tf
def loss_function(y_true, y_pred):

  #Cosine distance loss
  l_depth = K.mean(K.abs(y_pred - y_true), axis=-1)

  # edge loss for sharp edges
  '''
  dy_true, dx_true = tf.image.image_gradients(y_true)
  dy_pred, dx_pred = tf.image.image_gradients(y_pred)
  l_edges = K.mean(K.abs(dy_pred - dy_true) + K.abs(dx_pred - dx_true), axis=-1)
  '''
  # structural similarity loss
  l_ssim = K.clip((1 - tf.image.ssim(y_true, y_pred, 1.0)) * 0.5, 0, 1)

  # weightage
  w1, w3 = 1.0, 0.1
  #+ (w2 * K.mean(l_edges)) w2=1.0
  return (w1 * l_ssim) + (w3 * K.mean(l_depth))
def accuracy_function(y_true, y_pred):
  return K.mean(K.equal(K.round(y_true), K.round(y_pred)))
model=tf.keras.models.load_model('/content/drive/MyDrive/depth_model.h5', custom_objects={'loss_function':loss_function, 'accuracy_function':accuracy_function}, compile=False)

model.summary()

from keras.preprocessing import image
def load_image(img_path, show=False):

    img = image.load_img(img_path, target_size=(192, 640))
    img_tensor = image.img_to_array(img)                    # (height, width, channels)
    img_tensor = np.expand_dims(img_tensor, axis=0)         # (1, height, width, channels), add a dimension because the model expects this shape: (batch_size, height, width, channels)
    img_tensor /= 255.                                      # imshow expects values in the range [0, 1]

    if show:
        plt.imshow(img_tensor[0])
        plt.axis('off')
        plt.show()

    return img_tensor

new_image = load_image('/content/drive/MyDrive/test_image/3.jpg')

pred = model.predict(new_image)

pred=(1/pred)

from PIL import Image
plt.figure(figsize=(20,10))
image=train_image[3]
image=cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
plt.subplot(1,3,1)
plt.axis('off')
plt.imshow(image)
plt.title('Input image')

predic=np.squeeze(pred)
'''
predic=np.reshape(pred, [192,640,1])
print(predic.shape)
np_img=np.squeeze(predic, axis=2)
'''
im = Image.fromarray(1/predic)
im=Image.fromarray((predic * 255).astype(np.uint8))
plt.subplot(1,3,2)
plt.axis("off")
plt.imshow(im, cmap='inferno_r')
plt.title('Predict depth')
plt.axis("off")

plt.imshow(im, cmap='inferno_r')

from PIL import Image
im.save("/content/drive/MyDrive/xyz.jpeg")

"""Normal"""

model_2=tf.keras.models.load_model('/content/drive/MyDrive/normal_model.h5',custom_objects={'accuracy_function':accuracy_function}, compile=False)

npred=model_2.predict(new_image)
#print(npred)

from PIL import Image
plt.figure(figsize=(20,10))
image=train_image[3]
image=cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
plt.subplot(1,3,1)
plt.axis('off')
plt.imshow(image)
plt.title('Input image')
#cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

npredic=np.squeeze(npred)
#npredic=plt.imshow(npredic)
#nim = Image.fromarray(npredic)
#nim=Image.fromarray((npred * 255).astype(np.uint8))
npredic=cv2.cvtColor(npredic, cv2.COLOR_BGR2RGB)
plt.subplot(1,3,2)
plt.axis("off")
plt.imshow(npredic)
plt.title('Predict normal')
plt.axis("off")

npredi=Image.fromarray(np.uint8(npredic))
npredi.save("/content/drive/MyDrive/xyz1.jpeg")

cap=cv2.VideoCapture(0)

while cap.isOpened():
  ret, frame = cap.read()
  cv2_imshow('CV2Frame', frame)
  if cv2.waitKey(10) & 0xFF == ord('q'):
    cap.release()
    cv2.destroyAllWindows()

"""video"""

from IPython.display import display, Javascript
from google.colab.output import eval_js
from base64 import b64decode

def take_photo(filename='photo.jpg', quality=0.8):
  js = Javascript('''
    async function takePhoto(quality) {
      const div = document.createElement('div');
      const capture = document.createElement('button');
      capture.textContent = 'Capture';
      div.appendChild(capture);

      const video = document.createElement('video');
      video.style.display = 'block';
      const stream = await navigator.mediaDevices.getUserMedia({video: true});

      document.body.appendChild(div);
      div.appendChild(video);
      video.srcObject = stream;
      await video.play();

      // Resize the output to fit the video element.
      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);

      // Wait for Capture to be clicked.
      await new Promise((resolve) => capture.onclick = resolve);

      const canvas = document.createElement('canvas');
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
      canvas.getContext('2d').drawImage(video, 0, 0);
      stream.getVideoTracks()[0].stop();
      div.remove();
      return canvas.toDataURL('image/jpeg', quality);
    }
    ''')
  display(js)
  data = eval_js('takePhoto({})'.format(quality))
  binary = b64decode(data.split(',')[1])
  with open(filename, 'wb') as f:
    f.write(binary)
  return filename

from IPython.display import Image
try:
  filename = take_photo()
  print('Saved to {}'.format(filename))

  # Show the image which was just taken.
  display(Image(filename))
except Exception as err:
  # Errors will be thrown if the user does not have a webcam or if they do not
  # grant the page permission to access it.
  print(str(err))